#!/usr/bin/env python3
"""
æ–‡æ¡£é—®ç­”ç³»ç»Ÿä¸»å…¥å£æ–‡ä»¶
"""

import os
import sys
import logging
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.vectorstores.vector_store import VectorStoreManager
from src.chains.qa_chain import DocumentQAChain
from src.config.settings import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def build_vector_store(force_rebuild: bool = False, use_openai: bool = False):
    """æ„å»ºå‘é‡å­˜å‚¨"""
    logger.info("å¼€å§‹æ„å»ºå‘é‡å­˜å‚¨...")
    
    try:
        vector_manager = VectorStoreManager(use_openai_embeddings=use_openai)
        vector_manager.get_or_create_vector_store(force_recreate=force_rebuild)
        logger.info("å‘é‡å­˜å‚¨æ„å»ºå®Œæˆ")
        return vector_manager
    except Exception as e:
        logger.error(f"æ„å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}")
        raise





def start_api_server():
    """å¯åŠ¨APIæœåŠ¡å™¨"""
    logger.info("å¯åŠ¨APIæœåŠ¡å™¨...")
    
    try:
        import uvicorn
        from src.api.main import app
        
        uvicorn.run(
            app,
            host=settings.api_host,
            port=settings.api_port,
            reload=False
        )
    except Exception as e:
        logger.error(f"å¯åŠ¨APIæœåŠ¡å™¨å¤±è´¥: {str(e)}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
    
    # æ·»åŠ å­å‘½ä»¤
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # äº¤äº’æ¨¡å¼
    chat_parser = subparsers.add_parser("chat", help="å¯åŠ¨äº¤äº’å¼é—®ç­”")
    chat_parser.add_argument("--model", default=None, help="æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹")
    chat_parser.add_argument("--session", default="default", help="ä¼šè¯ID")
    chat_parser.add_argument("--no-memory", action="store_true", help="ä¸ä½¿ç”¨è®°å¿†åŠŸèƒ½")
    chat_parser.add_argument("--conversational", action="store_true", help="ä½¿ç”¨å¯¹è¯å¼æ£€ç´¢")
    chat_parser.add_argument("--use-agent", action="store_true", help="ä½¿ç”¨Agentæ¶æ„è€ŒéChainæ¶æ„")
    
    # æœåŠ¡å™¨æ¨¡å¼
    server_parser = subparsers.add_parser("server", help="å¯åŠ¨APIæœåŠ¡å™¨")
    
    # å‘é‡å­˜å‚¨ç®¡ç†
    vector_parser = subparsers.add_parser("vector", help="å‘é‡å­˜å‚¨ç®¡ç†")
    vector_subparsers = vector_parser.add_subparsers(dest="vector_action")
    
    rebuild_parser = vector_subparsers.add_parser("rebuild", help="é‡å»ºå‘é‡å­˜å‚¨")
    rebuild_parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡å»º")
    
    info_parser = vector_subparsers.add_parser("info", help="æ˜¾ç¤ºå‘é‡å­˜å‚¨ä¿¡æ¯")
    
    # è¯„ä¼°å‘½ä»¤
    eval_parser = subparsers.add_parser("eval", help="æ¨¡å‹è¯„ä¼°")
    eval_subparsers = eval_parser.add_subparsers(dest="eval_action")
    
    # åˆ›å»ºæ•°æ®é›†
    create_dataset_parser = eval_subparsers.add_parser("create-dataset", help="åˆ›å»ºè¯„ä¼°æ•°æ®é›†")
    create_dataset_parser.add_argument("--name", help="æ•°æ®é›†åç§°ï¼ˆåˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†æ—¶å¿…éœ€ï¼‰")
    create_dataset_parser.add_argument("--description", default="", help="æ•°æ®é›†æè¿°")
    create_dataset_parser.add_argument("--default", action="store_true", help="åˆ›å»ºé»˜è®¤æ•°æ®é›†")
    
    # åˆ—å‡ºæ•°æ®é›†
    list_datasets_parser = eval_subparsers.add_parser("list-datasets", help="åˆ—å‡ºæ‰€æœ‰æ•°æ®é›†")
    
    # è¿è¡Œè¯„ä¼°
    run_eval_parser = eval_subparsers.add_parser("run", help="è¿è¡Œè¯„ä¼°")
    run_eval_parser.add_argument("--dataset", required=True, help="æ•°æ®é›†åç§°")
    run_eval_parser.add_argument("--evaluators", nargs="+", 
                                default=["accuracy", "relevance", "helpfulness", "groundedness"],
                                help="è¯„ä¼°å™¨ç±»å‹")
    run_eval_parser.add_argument("--conversational", action="store_true", help="ä½¿ç”¨å¯¹è¯å¼æ£€ç´¢é“¾")
    run_eval_parser.add_argument("--concurrency", type=int, default=3, help="å¹¶å‘æ•°é‡")
    
    # åˆ—å‡ºæŠ¥å‘Š
    list_reports_parser = eval_subparsers.add_parser("list-reports", help="åˆ—å‡ºè¯„ä¼°æŠ¥å‘Š")
    
    # æŸ¥çœ‹æŠ¥å‘Š
    view_report_parser = eval_subparsers.add_parser("view-report", help="æŸ¥çœ‹è¯„ä¼°æŠ¥å‘Š")
    view_report_parser.add_argument("--file", required=True, help="æŠ¥å‘Šæ–‡ä»¶è·¯å¾„")
    
    # ç”Ÿæˆæ±‡æ€»
    summary_parser = eval_subparsers.add_parser("summary", help="ç”Ÿæˆè¯„ä¼°æ±‡æ€»")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        if args.command == "chat":
            handle_chat_command(args)
        elif args.command == "server":
            handle_server_command()
        elif args.command == "vector":
            handle_vector_command(args)
        elif args.command == "eval":
            handle_eval_command(args)
        else:
            logger.error(f"æœªçŸ¥å‘½ä»¤: {args.command}")
            
    except KeyboardInterrupt:
        logger.info("ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æ‰§è¡Œå‘½ä»¤å¤±è´¥: {str(e)}")
        if logger.level == logging.DEBUG:
            import traceback
            traceback.print_exc()


def handle_eval_command(args):
    """å¤„ç†è¯„ä¼°å‘½ä»¤"""
    if not args.eval_action:
        logger.error("è¯·æŒ‡å®šè¯„ä¼°æ“ä½œ")
        return
    
    if args.eval_action == "create-dataset":
        handle_create_dataset(args)
    elif args.eval_action == "list-datasets":
        handle_list_datasets()
    elif args.eval_action == "run":
        handle_run_evaluation(args)
    elif args.eval_action == "list-reports":
        handle_list_reports()
    elif args.eval_action == "view-report":
        handle_view_report(args)
    elif args.eval_action == "summary":
        handle_evaluation_summary()
    else:
        logger.error(f"æœªçŸ¥çš„è¯„ä¼°æ“ä½œ: {args.eval_action}")


def handle_create_dataset(args):
    """å¤„ç†åˆ›å»ºæ•°æ®é›†å‘½ä»¤"""
    try:
        from src.evaluation.datasets import DatasetManager, DatasetBuilder
        
        dataset_manager = DatasetManager()
        
        if args.default:
            # åˆ›å»ºé»˜è®¤æ•°æ®é›†
            dataset_manager.create_default_datasets()
            datasets = dataset_manager.list_datasets()
            logger.info(f"é»˜è®¤æ•°æ®é›†å·²åˆ›å»º: {datasets}")
        else:
            # åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›† - éœ€è¦åç§°
            if not args.name:
                logger.error("åˆ›å»ºè‡ªå®šä¹‰æ•°æ®é›†æ—¶å¿…é¡»æä¾› --name å‚æ•°")
                return
            
            from src.evaluation.datasets import EvaluationDataset
            dataset = EvaluationDataset(name=args.name, description=args.description)
            file_path = dataset_manager.save_dataset(dataset)
            logger.info(f"æ•°æ®é›† '{args.name}' å·²åˆ›å»º: {file_path}")
            
    except Exception as e:
        logger.error(f"åˆ›å»ºæ•°æ®é›†å¤±è´¥: {str(e)}")


def handle_list_datasets():
    """å¤„ç†åˆ—å‡ºæ•°æ®é›†å‘½ä»¤"""
    try:
        from src.evaluation.datasets import DatasetManager
        
        dataset_manager = DatasetManager()
        datasets = dataset_manager.list_datasets()
        
        if datasets:
            logger.info("å¯ç”¨çš„è¯„ä¼°æ•°æ®é›†:")
            for dataset_name in datasets:
                logger.info(f"  - {dataset_name}")
        else:
            logger.info("æ²¡æœ‰æ‰¾åˆ°è¯„ä¼°æ•°æ®é›†")
            
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ•°æ®é›†å¤±è´¥: {str(e)}")


def handle_run_evaluation(args):
    """å¤„ç†è¿è¡Œè¯„ä¼°å‘½ä»¤"""
    try:
        import asyncio
        from src.evaluation.datasets import DatasetManager
        from src.evaluation.runners import EvaluationRunner, EvaluationManager
        from src.vectorstores.vector_store import VectorStoreManager
        from src.chains.qa_chain import DocumentQAChain, ConversationalRetrievalChain
        
        # åˆå§‹åŒ–ç»„ä»¶
        logger.info("åˆå§‹åŒ–ç»„ä»¶...")
        vector_store_manager = VectorStoreManager(use_openai_embeddings=False)
        vector_store_manager.get_or_create_vector_store()
        
        qa_chain = DocumentQAChain(vector_store_manager=vector_store_manager, use_memory=True)
        conversational_chain = ConversationalRetrievalChain(vector_store_manager=vector_store_manager)
        
        # åŠ è½½æ•°æ®é›†
        dataset_manager = DatasetManager()
        dataset = dataset_manager.load_dataset(args.dataset)
        if not dataset:
            logger.error(f"æ•°æ®é›† '{args.dataset}' ä¸å­˜åœ¨")
            return
        
        # åˆ›å»ºè¯„ä¼°è¿è¡Œå™¨
        runner = EvaluationRunner(qa_chain=qa_chain, conversational_chain=conversational_chain)
        
        # è¿è¡Œè¯„ä¼°
        logger.info(f"å¼€å§‹è¯„ä¼°æ•°æ®é›†: {args.dataset}")
        
        async def run_async_evaluation():
            return await runner.run_evaluation(
                dataset=dataset,
                evaluator_types=args.evaluators,
                use_conversational=args.conversational,
                max_concurrency=args.concurrency
            )
        
        report = asyncio.run(run_async_evaluation())
        
        # ä¿å­˜æŠ¥å‘Š
        eval_manager = EvaluationManager()
        report_file = eval_manager.save_report(report)
        
        logger.info(f"è¯„ä¼°å®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
    except Exception as e:
        logger.error(f"è¿è¡Œè¯„ä¼°å¤±è´¥: {str(e)}")


def handle_list_reports():
    """å¤„ç†åˆ—å‡ºæŠ¥å‘Šå‘½ä»¤"""
    try:
        from src.evaluation.runners import EvaluationManager
        
        eval_manager = EvaluationManager()
        reports = eval_manager.list_reports()
        
        if reports:
            logger.info("è¯„ä¼°æŠ¥å‘Šæ–‡ä»¶:")
            for report_file in reports:
                logger.info(f"  - {report_file}")
        else:
            logger.info("æ²¡æœ‰æ‰¾åˆ°è¯„ä¼°æŠ¥å‘Š")
            
    except Exception as e:
        logger.error(f"åˆ—å‡ºæŠ¥å‘Šå¤±è´¥: {str(e)}")


def handle_view_report(args):
    """å¤„ç†æŸ¥çœ‹æŠ¥å‘Šå‘½ä»¤"""
    try:
        from src.evaluation.runners import EvaluationManager
        
        eval_manager = EvaluationManager()
        report = eval_manager.load_report(args.file)
        
        if not report:
            logger.error(f"æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
            return
        
        # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
        print("=" * 60)
        print(f"è¯„ä¼°æŠ¥å‘Š: {report.dataset_name}")
        print("=" * 60)
        print(f"æ—¶é—´æˆ³: {report.timestamp}")
        print(f"æ€»æ ·ä¾‹æ•°: {report.total_examples}")
        print(f"æ‰§è¡Œæ—¶é—´: {report.execution_time:.2f}ç§’")
        print(f"è¯„ä¼°å™¨: {', '.join(report.evaluator_names)}")
        print("\nå¹³å‡åˆ†æ•°:")
        
        for evaluator_name, score in report.avg_scores.items():
            print(f"  {evaluator_name}: {score:.3f}")
        
        print("\n" + "=" * 60)
        
    except Exception as e:
        logger.error(f"æŸ¥çœ‹æŠ¥å‘Šå¤±è´¥: {str(e)}")


def handle_evaluation_summary():
    """å¤„ç†è¯„ä¼°æ±‡æ€»å‘½ä»¤"""
    try:
        from src.evaluation.runners import EvaluationManager
        
        eval_manager = EvaluationManager()
        report_files = eval_manager.list_reports()
        
        reports = []
        for report_file in report_files:
            report = eval_manager.load_report(report_file)
            if report:
                reports.append(report)
        
        if not reports:
            logger.info("æ²¡æœ‰æ‰¾åˆ°è¯„ä¼°æŠ¥å‘Š")
            return
        
        summary = eval_manager.generate_summary_report(reports)
        
        # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
        print("=" * 60)
        print("è¯„ä¼°æ±‡æ€»æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ€»æŠ¥å‘Šæ•°: {summary.get('total_reports', 0)}")
        print(f"è¯„ä¼°çš„æ•°æ®é›†: {', '.join(summary.get('datasets_evaluated', []))}")
        
        print("\nå„è¯„ä¼°å™¨å¹³å‡åˆ†æ•°:")
        for evaluator_name, stats in summary.get('avg_scores_by_evaluator', {}).items():
            print(f"  {evaluator_name}:")
            print(f"    å‡å€¼: {stats['mean']:.3f}")
            print(f"    æœ€å°å€¼: {stats['min']:.3f}")
            print(f"    æœ€å¤§å€¼: {stats['max']:.3f}")
        
        best = summary.get('best_performing_dataset')
        if best:
            print(f"\nè¡¨ç°æœ€å¥½çš„æ•°æ®é›†: {best['name']} (åˆ†æ•°: {best['score']:.3f})")
        
        worst = summary.get('worst_performing_dataset')
        if worst:
            print(f"è¡¨ç°æœ€å·®çš„æ•°æ®é›†: {worst['name']} (åˆ†æ•°: {worst['score']:.3f})")
        
        print("=" * 60)
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {str(e)}")


def handle_chat_command(args):
    """å¤„ç†èŠå¤©å‘½ä»¤"""
    try:
        from src.vectorstores.vector_store import VectorStoreManager
        from src.chains.qa_chain import DocumentQAChain, ConversationalRetrievalChain
        from src.agents.rag_agent import DocumentQAAgent, ConversationalRetrievalAgent
        from src.agents.sql_agent import SQLAgent
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        vector_manager = VectorStoreManager(use_openai_embeddings=False)
        vector_manager.get_or_create_vector_store()
        
        # åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿï¼ˆChainæˆ–Agentï¼‰
        if args.use_agent:
            # ä½¿ç”¨Agentæ¶æ„
            if args.conversational:
                qa_system = ConversationalRetrievalAgent(vector_store_manager=vector_manager)
                print("ä½¿ç”¨å¯¹è¯å¼æ£€ç´¢Agent ğŸ¤–")
            else:
                use_memory = not args.no_memory
                qa_system = DocumentQAAgent(
                    vector_store_manager=vector_manager,
                    model_name=args.model,
                    use_memory=use_memory
                )
                print(f"ä½¿ç”¨æ–‡æ¡£é—®ç­”Agent ğŸ¤–ï¼Œè®°å¿†åŠŸèƒ½: {'å¼€å¯' if use_memory else 'å…³é—­'}")
        else:
            # ä½¿ç”¨Chainæ¶æ„
            if args.conversational:
                qa_system = ConversationalRetrievalChain(vector_store_manager=vector_manager)
                print("ä½¿ç”¨å¯¹è¯å¼æ£€ç´¢Chain â›“ï¸")
            else:
                use_memory = not args.no_memory
                qa_system = DocumentQAChain(
                    vector_store_manager=vector_manager,
                    model_name=args.model,
                    use_memory=use_memory
                )
                print(f"ä½¿ç”¨æ ‡å‡†é—®ç­”Chain â›“ï¸ï¼Œè®°å¿†åŠŸèƒ½: {'å¼€å¯' if use_memory else 'å…³é—­'}")
        
        qa_chain = qa_system  # ä¿æŒå˜é‡åå…¼å®¹æ€§
        
        # åˆå§‹åŒ–SQL Agent
        try:
            sql_agent = SQLAgent(use_memory=True, verbose=False)
            sql_available = True
            print("SQL Agent åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            sql_agent = None
            sql_available = False
            print(f"SQL Agent åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        
        print("\n=== æ™ºèƒ½é—®ç­”ç³»ç»Ÿ ===")
        print("ğŸ“„ æ–‡æ¡£é—®ç­” | ğŸ—ƒï¸ SQLæŸ¥è¯¢")
        print("è¾“å…¥é—®é¢˜å¼€å§‹å¯¹è¯ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("è¾“å…¥ 'clear' æ¸…ç©ºè®°å¿†")
        print("è¾“å…¥ 'sql:' å‰ç¼€è¿›è¡ŒSQLæŸ¥è¯¢")
        print("è¾“å…¥ 'mode doc' åˆ‡æ¢åˆ°æ–‡æ¡£é—®ç­”æ¨¡å¼")
        print("è¾“å…¥ 'mode sql' åˆ‡æ¢åˆ°SQLæŸ¥è¯¢æ¨¡å¼")
        print("=" * 50)
        
        session_id = args.session
        current_mode = "doc"  # é»˜è®¤æ–‡æ¡£æ¨¡å¼
        print(f"å½“å‰æ¨¡å¼: {'ğŸ“„ æ–‡æ¡£é—®ç­”' if current_mode == 'doc' else 'ğŸ—ƒï¸ SQLæŸ¥è¯¢'}")
        
        while True:
            try:
                mode_indicator = "ğŸ“„" if current_mode == "doc" else "ğŸ—ƒï¸"
                question = input(f"\n{mode_indicator} é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("å†è§ï¼")
                    break
                
                if question.lower() in ['clear', 'æ¸…ç©º']:
                    if current_mode == "doc":
                        if hasattr(qa_chain, 'clear_memory'):
                            qa_chain.clear_memory(session_id)
                        elif hasattr(qa_chain, 'memory_manager'):
                            qa_chain.memory_manager.clear_memory(session_id)
                    elif current_mode == "sql" and sql_available:
                        sql_agent.clear_memory(session_id)
                    print("è®°å¿†å·²æ¸…ç©º")
                    continue
                
                if question.lower() == 'mode doc':
                    current_mode = "doc"
                    print("å·²åˆ‡æ¢åˆ°æ–‡æ¡£é—®ç­”æ¨¡å¼ ğŸ“„")
                    continue
                
                if question.lower() == 'mode sql':
                    if sql_available:
                        current_mode = "sql"
                        print("å·²åˆ‡æ¢åˆ°SQLæŸ¥è¯¢æ¨¡å¼ ğŸ—ƒï¸")
                    else:
                        print("SQL Agentä¸å¯ç”¨")
                    continue
                
                if not question:
                    continue
                
                # å¤„ç†SQLæŸ¥è¯¢ï¼ˆæ— è®ºå½“å‰æ¨¡å¼ï¼‰
                if question.lower().startswith('sql:'):
                    if not sql_available:
                        print("SQL Agentä¸å¯ç”¨")
                        continue
                    
                    sql_question = question[4:].strip()
                    print("ğŸ—ƒï¸ SQLæŸ¥è¯¢ä¸­...")
                    result = sql_agent.query(sql_question, session_id=session_id)
                    
                    print(f"\nç­”æ¡ˆ: {result['answer']}")
                    if not result['success'] and result.get('error'):
                        print(f"é”™è¯¯: {result['error']}")
                    continue
                
                # æ ¹æ®å½“å‰æ¨¡å¼å¤„ç†æŸ¥è¯¢
                if current_mode == "doc":
                    print("ğŸ“„ æ–‡æ¡£æ£€ç´¢ä¸­...")
                    
                    if args.conversational:
                        if args.use_agent:
                            # Agentç‰ˆæœ¬ï¼šå¯¹è¯å¼æ£€ç´¢Agent
                            result = qa_chain.invoke(question=question, chat_history=[])
                        else:
                            # Chainç‰ˆæœ¬ï¼šå¯¹è¯å¼æ£€ç´¢é“¾
                            result = qa_chain.invoke(question=question, session_id=session_id)
                    else:
                        # æ ‡å‡†é—®ç­”ï¼ˆAgentæˆ–Chainï¼‰
                        result = qa_chain.invoke(question, session_id)
                    
                    print(f"\nç­”æ¡ˆ: {result['answer']}")
                    
                    # æ˜¾ç¤ºAgentçš„ä¸­é—´æ­¥éª¤ï¼ˆä»…Agentç‰ˆæœ¬ï¼‰
                    if args.use_agent and result.get('intermediate_steps'):
                        print(f"\nğŸ¤– Agentæ‰§è¡Œæ­¥éª¤({len(result['intermediate_steps'])}ä¸ª):")
                        for i, step in enumerate(result['intermediate_steps'][:2], 1):
                            if hasattr(step, '__dict__'):
                                print(f"  {i}. {step}")
                            else:
                                print(f"  {i}. {str(step)[:100]}...")
                    
                    # æ˜¾ç¤ºç›¸å…³æ–‡æ¡£
                    if result.get('relevant_documents'):
                        print(f"\nğŸ“š ç›¸å…³æ–‡æ¡£({len(result['relevant_documents'])}ä¸ª):")
                        for i, doc in enumerate(result['relevant_documents'][:2], 1):
                            source = doc['metadata'].get('source_file', 'Unknown')
                            content = doc['content'][:200] + "..." if len(doc['content']) > 200 else doc['content']
                            print(f"  {i}. æ¥æº: {source}")
                            print(f"     å†…å®¹: {content}")
                
                elif current_mode == "sql":
                    if not sql_available:
                        print("SQL Agentä¸å¯ç”¨ï¼Œè¯·åˆ‡æ¢åˆ°æ–‡æ¡£æ¨¡å¼")
                        continue
                    
                    print("ğŸ—ƒï¸ SQLæŸ¥è¯¢ä¸­...")
                    result = sql_agent.query(question, session_id=session_id)
                    
                    print(f"\nç­”æ¡ˆ: {result['answer']}")
                    if not result['success'] and result.get('error'):
                        print(f"é”™è¯¯: {result['error']}")
                
            except KeyboardInterrupt:
                print("\n\nç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                logger.error(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
                print(f"é”™è¯¯: {str(e)}")
                
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–èŠå¤©æ¨¡å¼å¤±è´¥: {str(e)}")


def handle_server_command():
    """å¤„ç†æœåŠ¡å™¨å‘½ä»¤"""
    try:
        import uvicorn
        from src.api.main import app
        
        logger.info("å¯åŠ¨APIæœåŠ¡å™¨...")
        uvicorn.run(
            app,
            host=settings.api_host,
            port=settings.api_port,
            reload=False
        )
    except Exception as e:
        logger.error(f"å¯åŠ¨APIæœåŠ¡å™¨å¤±è´¥: {str(e)}")


def handle_vector_command(args):
    """å¤„ç†å‘é‡å­˜å‚¨å‘½ä»¤"""
    if not args.vector_action:
        logger.error("è¯·æŒ‡å®šå‘é‡å­˜å‚¨æ“ä½œ")
        return
    
    try:
        from src.vectorstores.vector_store import VectorStoreManager
        
        if args.vector_action == "rebuild":
            vector_manager = VectorStoreManager(use_openai_embeddings=False)
            vector_manager.get_or_create_vector_store(force_recreate=args.force)
            logger.info("å‘é‡å­˜å‚¨é‡å»ºå®Œæˆ")
            
        elif args.vector_action == "info":
            vector_manager = VectorStoreManager(use_openai_embeddings=False)
            vector_store = vector_manager.get_or_create_vector_store()
            
            print("=" * 50)
            print("å‘é‡å­˜å‚¨ä¿¡æ¯")
            print("=" * 50)
            print(f"å­˜å‚¨è·¯å¾„: {vector_manager.vector_store_path}")
            print(f"å­˜å‚¨ç±»å‹: {type(vector_store).__name__}")
            
            # å°è¯•è·å–æ–‡æ¡£æ•°é‡
            try:
                if hasattr(vector_store, '_collection'):
                    count = vector_store._collection.count()
                    print(f"æ–‡æ¡£æ•°é‡: {count}")
                else:
                    print("æ–‡æ¡£æ•°é‡: æ— æ³•è·å–")
            except:
                print("æ–‡æ¡£æ•°é‡: æ— æ³•è·å–")
            
            print("=" * 50)
            
        else:
            logger.error(f"æœªçŸ¥çš„å‘é‡å­˜å‚¨æ“ä½œ: {args.vector_action}")
            
    except Exception as e:
        logger.error(f"å‘é‡å­˜å‚¨æ“ä½œå¤±è´¥: {str(e)}")


if __name__ == "__main__":
    main() 